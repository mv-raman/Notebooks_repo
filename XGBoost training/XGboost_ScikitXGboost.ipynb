{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain=xgb.DMatrix('./data/agaricus.txt.train')\n",
    "dtest=xgb.DMatrix('./data/agaricus.txt.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train col: 127 & train rows: 127\n",
      "test col: 127 & train rows: 127\n"
     ]
    }
   ],
   "source": [
    "print(\"train col: {0} & train rows: {1}\".format(dtrain.num_col(),dtrain.num_col()))\n",
    "print(\"test col: {0} & train rows: {1}\".format(dtest.num_col(),dtest.num_col()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dtrain.get_label()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':2,\n",
    "    'silent':1,\n",
    "    'eta':1\n",
    "}\n",
    "\n",
    "num_rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-error:0.042831\ttrain-error:0.046522\n",
      "[1]\ttest-error:0.021726\ttrain-error:0.022263\n",
      "[2]\ttest-error:0.006207\ttrain-error:0.007063\n",
      "[3]\ttest-error:0.018001\ttrain-error:0.0152\n",
      "[4]\ttest-error:0.006207\ttrain-error:0.007063\n"
     ]
    }
   ],
   "source": [
    "#create watchlist\n",
    "watchlist=[(dtest,'test'),(dtrain,'train')]\n",
    "bst=xgb.train(params,dtrain,num_rounds,watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08073306, 0.92217326, 0.08073306, ..., 0.98059034, 0.01182149,\n",
       "       0.98059034], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_prob=bst.predict(dtest)\n",
    "preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ans=dtest.get_label()\n",
    "pred_ans=preds_prob>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for i in range(len(real_ans)):\n",
    "    if(real_ans[i]==pred_ans[i]):\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions are:1601/1611\n",
      "error percentage:0.0062\n"
     ]
    }
   ],
   "source": [
    "print('correct predictions are:{0}/{1}'.format(counter,len(pred_ans)))\n",
    "print('error percentage:{0:.4f}'.format(1-counter/len(pred_ans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using sklearn implenting xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=load_svmlight_files(('./data/agaricus.txt.train','./data/agaricus.txt.test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 6513 rows and 126 columns\n",
      "Test dataset contains 1611 rows and 126 columns\n",
      "Train possible labels: \n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset contains {0} rows and {1} columns\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"Test dataset contains {0} rows and {1} columns\".format(X_test.shape[0], X_test.shape[1]))\n",
    "print(\"Train possible labels: \")\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 1.0,\n",
    "    'silent': 1.0,\n",
    "    'n_estimators': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkat/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "bst=XGBClassifier(**params).fit(X_train,y_train)\n",
    "preds=bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 1601/1611\n",
      "Error: 0.0062\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if (y_test[i] == preds[i]):\n",
    "        correct += 1\n",
    "        \n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print('Predicted correctly: {0}/{1}'.format(correct, len(preds)))\n",
    "print('Error: {0:.4f}'.format(1-acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
